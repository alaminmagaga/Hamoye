{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "import IPython\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The main cause of the American Civil War was conflict over states' rights and slavery.\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Provide a concise fact about the event in history mentioned by the user briefly enough to fit as an MCQ option.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What was the main cause of the American Civil War?\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=40,\n",
    "    top_p=1\n",
    ")\n",
    "print(response.choices[0].message['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¿A qué hora es la reunión?\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Translate the following sentence into Spanish concisely to fit as an MCQ option.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What time is the meeting?\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=1,\n",
    "    max_tokens=40,\n",
    "    top_p=1\n",
    ")\n",
    "print(response.choices[0].message['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The economy is growing steadily due to consumer spending and investments in renewable energy, leading to record low unemployment rates.\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are to summarize the provided text into a concise form, maintaining the key points and context, briefly enough to fit as an MCQ option.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"The economy has been growing steadily over the past few quarters, driven by increases in consumer spending and substantial investments in renewable energy infrastructure. Unemployment rates have also fallen to record lows as new industries are creating more jobs.\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=100,\n",
    "    top_p=1\n",
    ")\n",
    "print(response.choices[0].message['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentiment of the text is negative.\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Classify the sentiment of the text provided by the user as positive, negative, or neutral.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"I had an awful experience at the restaurant. The food was bland and the service was slow.\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=10,\n",
    "    top_p=1\n",
    ")\n",
    "print(response.choices[0].message['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloud computing is a technology that allows users to access\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What is cloud computing?\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Explain the technical concept briefly enough to fit as an MCQ option.\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=10,\n",
    "    top_p=1\n",
    ")\n",
    "print(response.choices[0].message['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alan Turing is known as the father of computer science\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Who is known as the father of computer science?\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Provide a brief, accurate answer to the user’s question that can be used as an MCQ option.\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=10,\n",
    "    top_p=1\n",
    ")\n",
    "print(response.choices[0].message['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Ich liebe es zu reisen.\"\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You will be provided with a sentence in English, and your task is to translate it into German.\"\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"How do you say 'I love to travel' in German?\"\n",
    "        }\n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=64,\n",
    "    top_p=1\n",
    ")\n",
    "print(response.choices[0].message['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The internet was developed for researchers to communicate and share computing resources, now connecting millions of people and devices worldwide.\n"
     ]
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "         {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"Summarize the content into concise phrase suitable for MCQ answer option.\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"The internet was developed to help researchers communicate and share computing resources. Today, it connects millions of people and devices across the globe.\"\n",
    "        }\n",
    "       \n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=64,\n",
    "    top_p=1\n",
    ")\n",
    "print(response.choices[0].message['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "         {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a knowledgaeble assistant.A user will ask a question and you should provide a clear and concise answer briefly enough to fit into as an MCQ option.\"\n",
    "        },\n",
    "        \n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"What Causes the Northern Light\"\n",
    "        }\n",
    "       \n",
    "    ],\n",
    "    temperature=0,\n",
    "    max_tokens=64,\n",
    "    top_p=1\n",
    ")\n",
    "print(response.choices[0].message['content'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
